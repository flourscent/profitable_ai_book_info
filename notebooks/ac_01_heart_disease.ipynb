{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 사례 1: 불량품, 질병 판정의 자동화 (이진 분류, 재현율)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공통 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 처리\n",
    "\n",
    "# 불필요한 경고 메시지 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 글꼴 설정\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "elif platform.system() == 'Darwin':\n",
    "    plt.rc('font', family='Apple Gothic')\n",
    "\n",
    "# 데이터프레임 출력용 함수\n",
    "from IPython.display import display\n",
    "\n",
    "# 숫자 출력 조정\n",
    "# 넘파이 부동소수점 출력 자리수 설정\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# 판다스 부동소수점 출력 자리수 설정\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "# 데이터프레임 모든 필드 출력\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "\n",
    "# 그래프 글꼴 크기 설정\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "\n",
    "# 난수 시드\n",
    "random_seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동행렬 출력용 함수\n",
    "\n",
    "def make_cm(matrix, columns):\n",
    "    # matrix : 넘파이 배열\n",
    "    # columns : 필드명 리스트\n",
    "    n = len(columns)\n",
    "    \n",
    "    # '정답 데이터'를 n번 반복해 연접한 리스트\n",
    "    act = ['정답데이터'] * n\n",
    "    pred = ['예측결과'] * n\n",
    "    \n",
    "    # 데이터프레임 생성\n",
    "    cm = pd.DataFrame(matrix, \n",
    "        columns=[pred, columns], index=[act, columns])\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.4 데이터 읽어들이기부터 데이터 확인까지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필드 정보\n",
    "\n",
    "#### age\n",
    "나이\n",
    "\n",
    "#### sex\n",
    "성별\n",
    "* 1: 남성\n",
    "* 0: 여성\n",
    "\n",
    "#### cp\n",
    "흉통 종류\n",
    "* 1：전형적인 협심증\n",
    "* 2：비정형 협심증\n",
    "* 3：비협심성 흉통\n",
    "* 4：무증후성 \n",
    "\n",
    "#### trestbps\n",
    "안정시 혈압\n",
    "（입원 시점, 단위: mmHg）\n",
    "    \n",
    "#### chol\n",
    "혈장 콜레스테롤\n",
    "（mg / dl）\n",
    "\n",
    "#### fbs\n",
    "공복시 혈당   \n",
    "(> 120 (mg / dl）)\n",
    "* 1 참\n",
    "* 0 거짓\n",
    "\n",
    "#### restecg\n",
    "안정시 심전도\n",
    " \n",
    "* 0：정상\n",
    "* 1：ST-T파 이상（T파 반전 / ST 상승 혹은 억제 > 0.05 mV）\n",
    "* 2：좌심실 비대 가능성\n",
    "\n",
    "#### thalach\n",
    "최대 심박수\n",
    "\n",
    "#### exang\n",
    "운동 유발성 협심증\n",
    "* 1  예\n",
    "* 0  아니오\n",
    "    \n",
    "#### oldpeak\n",
    "ST 저하\n",
    "(안정시와 비교해 운동에 의해 유발되는 ST 저하)\n",
    "\n",
    "#### slope\n",
    "ST 세그먼트 기울기\n",
    "(피크 운동 ST 세그먼트 기울기)\n",
    "* 1 상승\n",
    "* 2 평탄\n",
    "* 3 하강\n",
    "\n",
    "#### ca \n",
    "주요 혈관 수\n",
    "(X선 투시촬영에서 착색된 주요 혈관 수 (0~3))\n",
    "\n",
    "\n",
    "#### thal\n",
    "탈륨 \n",
    "(탈륨 심장 스캔 결과)\n",
    "* 3 : 정상\n",
    "* 6 : 수정된 결함\n",
    "* 7 : 회복 가능한 결함\n",
    "\n",
    "\n",
    "#### num (목적변수)\n",
    "심장병 여부\n",
    "(혈관 조영 결과)\n",
    "* 0: 소견 있음\n",
    "* 1: 소견 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 읽어 들이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 심장 질환 공개 데이터 집합 읽어 들이기\n",
    "\n",
    "columns = [\n",
    "    '나이', '성별', '흉통종류', '안정시혈압',  '혈장콜레스테롤',\n",
    "    '공복시혈당', '안정시심전도',  '최대심박수',  '운동유발성협심증',\n",
    "    'ST저하', 'ST세그먼트기울기', '주요혈관수', '탈륨', '심장병여부'\n",
    "]\n",
    "\n",
    "# 공개 데이터 집합 URL\n",
    "url_hu = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data'\n",
    "\n",
    "# 데이터프레임으로 읽어 들이기\n",
    "# 누락값은 '?'으로 표기되며, 읽어들인 후에는 파이썬의 NaN으로 변환됨\n",
    "df_hu = pd.read_csv(url_hu, header=None, names=columns, na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터 전체 확인\n",
    "display(df_hu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 건수와 필드 수 확인\n",
    "print(df_hu.shape)\n",
    "print()\n",
    "\n",
    "# '심장병여부' 필드의 값 분포 확인\n",
    "print(df_hu['심장병여부'].value_counts())\n",
    "print()\n",
    "\n",
    "# 진단율 계산\n",
    "rate = df_hu['심장병여부'].value_counts()[1]/len(df_hu)\n",
    "print(f'진단율: {rate:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 히스토그램 그리기\n",
    "\n",
    "# 그래프 크기 조정\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 12)\n",
    "\n",
    "# 데이터프레임의 수치 필드를 대상으로 한 히스토그램 그리기\n",
    "df_hu.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락값 확인\n",
    "print(df_hu.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.5 데이터 전처리와 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 누락값 처리 방법\n",
    "\n",
    "* 안정시혈압: 평균\n",
    "* 혈장콜레스테롤: 평균\n",
    "* 공복시혈당: 0\n",
    "* 안정시심전도: 0\n",
    "* 최대심박수: 평균\n",
    "* 운동유발성협심증: 0   \n",
    "* ST세그먼트기울기: 2  \n",
    "----    \n",
    "* 주요혈관수: 필드 자체를 제거\n",
    "* 탈륨: 필드 자체를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균값 계산\n",
    "ave1 = df_hu['안정시혈압'].mean()\n",
    "ave2 = df_hu['혈장콜레스테롤'].mean()\n",
    "ave3 = df_hu['최대심박수'].mean()\n",
    "\n",
    "# 결과 확인\n",
    "print(f'안정시혈압: {ave1:.1f}  혈장콜레스테롤: {ave2:.1f}   최대심박수:{ave3:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락값 치환\n",
    "df2 = df_hu.fillna(\n",
    "    {'안정시혈압': ave1,\n",
    "    '혈장콜레스테롤': ave2,\n",
    "    '공복시혈당': 0,\n",
    "    '안정시심전도': 0,\n",
    "    '최대심박수': ave3,\n",
    "    '운동유발성협심증': 0,\n",
    "    'ST세그먼트기울기': 2}\n",
    ")\n",
    "\n",
    "# 필드 삭제\n",
    "df3 = df2.drop(['주요혈관수', '탈륨'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "print(df3.isnull().sum())\n",
    "display(df3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터와 정답 데이터 분할\n",
    "x = df3.drop('심장병여부', axis=1)\n",
    "y = df3['심장병여부'].values\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분할\n",
    "test_size=0.40\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "  x, y, test_size=test_size, random_state=random_seed,\n",
    "  stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.6 알고리즘 선택하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 알고리즘 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후보 알고리즘의 리스트\n",
    "\n",
    "# 로지스틱 회귀 (4.3.3)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algorithm1 = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "# 결정 트리 (4.3.6)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm2 = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "# 랜덤 포레스트 (4.3.7)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algorithm3 = RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "# XGBoost (4.3.8)\n",
    "from xgboost import XGBClassifier\n",
    "algorithm4 = XGBClassifier(random_state=random_seed)\n",
    "\n",
    "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증법을 이용해 최적의 알고리즘을 선택\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "for algorithm in algorithms:\n",
    "    # 교차 검증법\n",
    "    scores = cross_val_score(algorithm , x_train, y_train,\n",
    "        cv=stratifiedkfold, scoring='roc_auc')\n",
    "    score = scores.mean()\n",
    "    name = algorithm.__class__.__name__\n",
    "    print(f'평균 점수: {score:.4f}  개별 점수: {scores}  {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트의 성능이 가장 좋게 나왔으므로 랜덤 포레스트를 채택함\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.7 학습, 예측, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알고리즘 선택\n",
    "# 랜덤 포레스트를 선택함\n",
    "algorithm = RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "# 학습\n",
    "algorithm.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = algorithm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "\n",
    "# 혼동행렬을 출력\n",
    "from sklearn.metrics import confusion_matrix\n",
    "df_matrix = make_cm(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    ['소견없음', '소견있음'])\n",
    "display(df_matrix)\n",
    "\n",
    "# 정확률, 재현율, F-점수를 계산\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, \n",
    "    y_pred, average='binary')\n",
    "print(f'정확률: {precision:.4f}  재현율: {recall:.4f}  F-점수: {fscore:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1.8 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률의 도수분포 그래프\n",
    "\n",
    "# y=1일 확률\n",
    "y_proba1= algorithm.predict_proba(x_test)[:,1]\n",
    "\n",
    "# y_test=0, y_test=1인 경우로 데이터를 분할\n",
    "y0 = y_proba1[y_test==0]\n",
    "y1 = y_proba1[y_test==1]\n",
    "\n",
    "# 산포도 그리기\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title('확률의 도수분포')\n",
    "sns.distplot(y1, kde=False, norm_hist=True,\n",
    "    bins=10,color='b', label='소견있음')\n",
    "sns.distplot(y0, kde=False, norm_hist=True,\n",
    "    bins=10,color='k', label='소견없음')\n",
    "plt.xlabel('확률')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 역치 수정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict_proba 함수를 이용해 0.5외의 역치를 반영한 결과를 예측\n",
    "(4.4절 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 역치를 바꿔가며 예측 결과를 계산하는 함수\n",
    "def pred(algorithm, x, thres):\n",
    "    # 확률값(행렬)\n",
    "    y_proba = algorithm.predict_proba(x)\n",
    "    \n",
    "    # 예측결과 1의 확률\n",
    "    y_proba1 =  y_proba[:,1]\n",
    "    \n",
    "    # 예측결과 1일 확률이 역치보다 큰지 여부\n",
    "    y_pred = (y_proba1 > thres).astype(int)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 역치를 0.05단위로 바꿔가며 정확률, 재현율, F-점수를 계산\n",
    "thres_list = np.arange(0.5, 0, -0.05)\n",
    "\n",
    "for thres in thres_list:\n",
    "    y_pred2 = pred(algorithm, x_test, thres)\n",
    "    pred_sum =  y_pred2.sum()\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred2, average='binary')\n",
    "    print(f'역치: {thres:.2f} 합계: {pred_sum}  정확률: {precision:.4f}\\\n",
    "  재현율: {recall:.4f}  F-점수: {fscore:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현율을 중시해 역치를 0.25로 설정\n",
    "y_final = pred(algorithm, x_test, 0.25)\n",
    "\n",
    "# 혼동행렬을 출력\n",
    "from sklearn.metrics import confusion_matrix\n",
    "df_matrix4 = make_cm(\n",
    "    confusion_matrix(y_test, y_final),\n",
    "    ['소견없음', '소견있음'])\n",
    "display(df_matrix4)\n",
    "\n",
    "# 정확률, 재현율, F-점수를 계산\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "    y_test, y_final, average='binary')\n",
    "print(f'정확률: {precision:.4f}  재현율: {recall:.4f}  F-점수: {fscore:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
